package lexer;

import java.util.HashMap;
import java.util.Map;

public class Token {
	private final TokenType type;
	private final String lexme;
	
	static Token ofName(String lexme) {
		TokenType type = KEYWORDS.get(lexme);
			if ( type != null ) {
				return new Token(type, lexme);
			}
			else if( lexme.startsWith("#") ) { // 만약에 #으로 시작한 lexme일 경우에
		         if( lexme.endsWith("T") ) { // T로 끝나면 
		            return new Token(TokenType.TRUE, lexme); // TURE의 토큰타입과 그 lexme값의 토큰을 생성해서 리턴해준다.
		         }
		         else if( lexme.endsWith("F") ) { // F로 끝나면
		            return new Token(TokenType.FALSE, lexme); // FALSE의 토큰타입과 그 lexme값의 토큰을 생성해서 리턴해준다.
		         }
		         else  throw new ScannerException("invalid ID=" + lexme); 
		      }
			else {
	            return new Token(TokenType.ID, lexme);
	         }
		}
	
	Token(TokenType type, String lexme) {
		this.type = type;
		this.lexme = lexme;
	}
	public TokenType type() {
		TokenType type = KEYWORDS.get(this.lexme); // 토큰타입에서 맞는 키워드를 가져와서
		if ( type != null ) { // 만약에 키워드 일경우에는
			Token temp = ofName(this.lexme); // ofName으로 보내고
			return temp.type; // 그 값을 리턴해준다.
		}
		return this.type; // 키워드가 아니면 그냥 type을 리턴해준다.
	}
	public String lexme() {
		return this.lexme;
	}
	@Override
	public String toString() {
		return String.format("%s(%s)", type, lexme);
	}
	private static final Map<String,TokenType> KEYWORDS = new HashMap<>();
	static {
		KEYWORDS.put("define", TokenType.DEFINE);
		KEYWORDS.put("lambda", TokenType.LAMBDA);
		KEYWORDS.put("cond", TokenType.COND);
		KEYWORDS.put("quote", TokenType.QUOTE);
		KEYWORDS.put("not", TokenType.NOT);
		KEYWORDS.put("cdr", TokenType.CDR);
		KEYWORDS.put("car", TokenType.CAR);
		KEYWORDS.put("cons", TokenType.CONS);
		KEYWORDS.put("eq?", TokenType.EQ_Q);
		KEYWORDS.put("null?", TokenType.NULL_Q);
		KEYWORDS.put("atom?", TokenType.ATOM_Q);
	}
}